{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceMaskDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jGrZWbFu9Sf"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYH9G-OAsHnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76327639-bd86-4e02-cbd7-4011ce0ae852"
      },
      "source": [
        "!kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading face-mask-12k-images-dataset.zip to /content\n",
            " 94% 312M/330M [00:02<00:00, 138MB/s]\n",
            "100% 330M/330M [00:02<00:00, 133MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7DzBnAllg2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd00a523-e72e-457b-813c-346be31c7f65"
      },
      "source": [
        "!unzip -qq jangedoo/utkface-new.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open jangedoo/utkface-new.zip, jangedoo/utkface-new.zip.zip or jangedoo/utkface-new.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68bUlK_rvQrt"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten, Dense, MaxPool2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYR_0GzTr-iz"
      },
      "source": [
        "cd /content/drive/MyDrive/DeepLearningTasks/FaceMaskDetection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oySHWuSsLRD"
      },
      "source": [
        "batch_size = 4\n",
        "epochs = 10\n",
        "lr = 0.0001\n",
        "width = height = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqO7y3EysNWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9983bd0-6aea-4719-908a-fa51b144bd54"
      },
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    rescale = 1/.255,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_data = data_generator.flow_from_directory(\n",
        "    \"/content/Face Mask Dataset/Train\",\n",
        "    target_size = (width, height),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "val_data = data_generator.flow_from_directory(\n",
        "    \"/content/Face Mask Dataset/Validation\",\n",
        "    target_size = (width, height),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "print(np.bincount(train_data.labels))\n",
        "print(np.bincount(val_data.labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n",
            "[5000 5000]\n",
            "[400 400]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRTdyrG-wKDl"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 3)),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZFn-BdrmCZU"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                             metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n19mgaTmExB",
        "outputId": "dfe2ea6d-7d66-48f1-cf68-4ce99e6d9d3d"
      },
      "source": [
        "model.fit(train_data,\n",
        "          # steps_per_epoch=train_data.samples/batch_size,\n",
        "          validation_data=val_data,\n",
        "          # validation_steps=val_data.samples/batch_size,\n",
        "          epochs=epochs,\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2500/2500 [==============================] - 58s 23ms/step - loss: 0.1291 - accuracy: 0.9669 - val_loss: 0.0831 - val_accuracy: 0.9762\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 56s 22ms/step - loss: 0.0588 - accuracy: 0.9830 - val_loss: 0.0572 - val_accuracy: 0.9812\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 56s 22ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.0628 - val_accuracy: 0.9825\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 56s 22ms/step - loss: 0.0342 - accuracy: 0.9904 - val_loss: 0.0583 - val_accuracy: 0.9862\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 56s 22ms/step - loss: 0.0374 - accuracy: 0.9905 - val_loss: 0.0372 - val_accuracy: 0.9900\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 55s 22ms/step - loss: 0.0331 - accuracy: 0.9907 - val_loss: 0.1338 - val_accuracy: 0.9725\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 55s 22ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.0705 - val_accuracy: 0.9787\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 56s 22ms/step - loss: 0.0335 - accuracy: 0.9916 - val_loss: 0.0225 - val_accuracy: 0.9950\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 55s 22ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0262 - val_accuracy: 0.9925\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 56s 22ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0773 - val_accuracy: 0.9800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c0ea4a510>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO3j_7FlmnpC"
      },
      "source": [
        "# model.save(\"/content/drive/MyDrive/DeepLearningTasks/ GenderClassification/model4.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHCo-O5mmoTa",
        "outputId": "f15c850e-0341-4a22-8fd7-47b54a73aba7"
      },
      "source": [
        "test_data_path = '/content/Face Mask Dataset/Test'\n",
        "\n",
        "data_generator = ImageDataGenerator(rescale = 1/.255)\n",
        "\n",
        "test_data = data_generator.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(width, height),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 992 images belonging to 2 classes.\n",
            "248/248 [==============================] - 3s 13ms/step - loss: 0.1012 - accuracy: 0.9768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10123773664236069, 0.9768145084381104]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQn3F_ZAmreC",
        "outputId": "c9e019da-bcc2-4864-aa04-27d26a7323c8"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "Y_pred = model.predict(test_data)\n",
        "y_pred = np.argmax(Y_pred, axis = 1)\n",
        "print('confusion Matrix')\n",
        "print(confusion_matrix(test_data.classes, y_pred))\n",
        "\n",
        "target_names = list(test_data.class_indices.keys())\n",
        "print('Classification Report')\n",
        "print(classification_report(test_data.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion Matrix\n",
            "[[232 251]\n",
            " [242 267]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    WithMask       0.49      0.48      0.48       483\n",
            " WithoutMask       0.52      0.52      0.52       509\n",
            "\n",
            "    accuracy                           0.50       992\n",
            "   macro avg       0.50      0.50      0.50       992\n",
            "weighted avg       0.50      0.50      0.50       992\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxsk-oH0mG9Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}