{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxqpHZWJdSva"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K_9g_8LE6C-"
      },
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrKxRIxaE72e"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9IpE3R8dhY5",
        "outputId": "6cda8877-9273-4fb5-c2c7-fd9f471d2fbc"
      },
      "source": [
        "!kaggle datasets download -d ashishjangra27/gender-recognition-200k-images-celeba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading gender-recognition-200k-images-celeba.zip to /content\n",
            " 99% 1.31G/1.32G [00:08<00:00, 147MB/s]\n",
            "100% 1.32G/1.32G [00:08<00:00, 159MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bjeTk9td5RP"
      },
      "source": [
        "!unzip -qq gender-recognition-200k-images-celeba.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dihc_6qTk8Mm"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten, Dense, MaxPool2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from config import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZA1n12dhg4i",
        "outputId": "6f70abdc-c8b1-4e22-bedf-8b36fb3b116d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lAkrSVmlTL6"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_cEEoXhlSIM",
        "outputId": "95610842-d21b-4911-89ff-1c718f360ff9"
      },
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    rescale = 1/.255,\n",
        "    horizontal_flip=True,\n",
        "    # zoom_range=0.3,\n",
        "    # rotation_range=30\n",
        ")\n",
        "\n",
        "train_data = data_generator.flow_from_directory(\n",
        "    \"/content/Dataset/Train\",\n",
        "    target_size = (width, height),\n",
        "    batch_size = batch_size,\n",
        "    # class_mode = 'binary',\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "val_data = data_generator.flow_from_directory(\n",
        "    \"/content/Dataset/Validation\",\n",
        "    target_size = (width, height),\n",
        "    batch_size = batch_size,\n",
        "    # class_mode = 'binary',\n",
        "    class_mode = 'categorical',\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "print(np.bincount(train_data.labels))\n",
        "print(np.bincount(val_data.labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160000 images belonging to 2 classes.\n",
            "Found 22598 images belonging to 2 classes.\n",
            "[92845 67155]\n",
            "[13778  8820]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2aWeD8cnRp2"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 3)),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(2, activation='softmax')\n",
        "])\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxNqQlbeoobp"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                             metrics=['accuracy'])\n",
        "# model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
        "#               optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "#                              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJt2vA5boudP",
        "outputId": "e448982f-25a5-4a6d-99ed-b9642db565c1"
      },
      "source": [
        "model.fit(train_data,\n",
        "          steps_per_epoch=train_data.samples/batch_size,\n",
        "          validation_data=val_data,\n",
        "          validation_steps=val_data.samples/batch_size,\n",
        "          epochs=epochs,\n",
        "          class_weight={0: 1, 1: 1.4}\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "3333/3333 [==============================] - 453s 136ms/step - loss: 0.1649 - accuracy: 0.9438 - val_loss: 0.0849 - val_accuracy: 0.9667\n",
            "Epoch 2/15\n",
            "3333/3333 [==============================] - 444s 133ms/step - loss: 0.0855 - accuracy: 0.9720 - val_loss: 0.0725 - val_accuracy: 0.9714\n",
            "Epoch 3/15\n",
            "3333/3333 [==============================] - 444s 133ms/step - loss: 0.0691 - accuracy: 0.9780 - val_loss: 0.0782 - val_accuracy: 0.9705\n",
            "Epoch 4/15\n",
            "3333/3333 [==============================] - 445s 133ms/step - loss: 0.0567 - accuracy: 0.9823 - val_loss: 0.0621 - val_accuracy: 0.9761\n",
            "Epoch 5/15\n",
            "3333/3333 [==============================] - 444s 133ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.0810 - val_accuracy: 0.9703\n",
            "Epoch 6/15\n",
            "3333/3333 [==============================] - 444s 133ms/step - loss: 0.0389 - accuracy: 0.9883 - val_loss: 0.0692 - val_accuracy: 0.9752\n",
            "Epoch 7/15\n",
            "3333/3333 [==============================] - 445s 133ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.0640 - val_accuracy: 0.9795\n",
            "Epoch 8/15\n",
            "3333/3333 [==============================] - 446s 134ms/step - loss: 0.0274 - accuracy: 0.9920 - val_loss: 0.0646 - val_accuracy: 0.9793\n",
            "Epoch 9/15\n",
            "3333/3333 [==============================] - 445s 133ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0735 - val_accuracy: 0.9783\n",
            "Epoch 10/15\n",
            "3333/3333 [==============================] - 445s 133ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.0737 - val_accuracy: 0.9800\n",
            "Epoch 11/15\n",
            "3333/3333 [==============================] - 446s 134ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.0996 - val_accuracy: 0.9749\n",
            "Epoch 12/15\n",
            "3333/3333 [==============================] - 446s 134ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0721 - val_accuracy: 0.9795\n",
            "Epoch 13/15\n",
            "3333/3333 [==============================] - 445s 134ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.1012 - val_accuracy: 0.9774\n",
            "Epoch 14/15\n",
            "3333/3333 [==============================] - 443s 133ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0799 - val_accuracy: 0.9798\n",
            "Epoch 15/15\n",
            "3333/3333 [==============================] - 444s 133ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1069 - val_accuracy: 0.9784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29edfeb650>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp0x2hefrv_P"
      },
      "source": [
        "# %cd /content/drive/MyDrive/DeepLearningTasks/ GenderClassification\n",
        "model.save(\"/content/drive/MyDrive/DeepLearningTasks/ GenderClassification/model4.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN5LiykRsWEX"
      },
      "source": [
        "test_data_path = '/content/Dataset/Test'\n",
        "\n",
        "data_generator = ImageDataGenerator(rescale = 1/.255)\n",
        "\n",
        "test_data = data_generator.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(width, height),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fgTFQSEfdHV",
        "outputId": "9fcb2624-2ab5-4e08-d574-03f1b72de026"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "Y_pred = model.predict(test_data)\n",
        "y_pred = np.argmax(Y_pred, axis = 1)\n",
        "print('confusion Matrix')\n",
        "print(confusion_matrix(test_data.classes, y_pred))\n",
        "\n",
        "target_names = list(test_data.class_indices.keys())\n",
        "print('Classification Report')\n",
        "print(classification_report(test_data.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion Matrix\n",
            "[[6821 4721]\n",
            " [4880 3579]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Female       0.58      0.59      0.59     11542\n",
            "        Male       0.43      0.42      0.43      8459\n",
            "\n",
            "    accuracy                           0.52     20001\n",
            "   macro avg       0.51      0.51      0.51     20001\n",
            "weighted avg       0.52      0.52      0.52     20001\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWc-lbCgj9a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}